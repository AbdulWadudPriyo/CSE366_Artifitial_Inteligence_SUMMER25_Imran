{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Stacked Learning 1st Part"
      ],
      "metadata": {
        "id": "bvj1KUJ53t-0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YK7l74lzBFP",
        "outputId": "c7db3b6c-8047-47fd-dca5-725eaf86cf25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacked Model Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#1. Load DataSet\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "#2. Split DataSet\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#3. Define base learners\n",
        "base_learners = [\n",
        "    ('dt', DecisionTreeClassifier()),\n",
        "    ('svc', SVC(kernel='rbf', probability=True)),\n",
        "    ('rf', RandomForestClassifier(n_estimators=100))\n",
        "]\n",
        "\n",
        "#4. Define meta-learner (final estimator)\n",
        "meta_learner = LogisticRegression()\n",
        "\n",
        "#5. Create StackingClassifier\n",
        "stacked_model = StackingClassifier(\n",
        "    estimators=base_learners,\n",
        "    final_estimator=meta_learner,\n",
        "    cv=5,     #cross-validation for base models\n",
        "    passthrough=False, #if True, passes original features along with base outputs\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "#6. Train Stacked Model\n",
        "stacked_model.fit(X_train, y_train)\n",
        "\n",
        "#7. Make Predictions\n",
        "y_pred = stacked_model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Stacked Model Accuracy:\", acc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stacked Learning 2nd Part"
      ],
      "metadata": {
        "id": "RQ4j9jhl4B26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "#1. Load Dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "y_cat = to_categorical(y, num_classes=3)\n",
        "\n",
        "#2. Split into Train and Test\n",
        "X_train, X_test, y_train_cat, y_test_cat, y_train, y_test = train_test_split(\n",
        "    X, y_cat, y, test_size=0.2, random_state=4\n",
        ")\n",
        "\n",
        "#3. Define Function to create a model\n",
        "def create_model_1():\n",
        "  model = Sequential([\n",
        "      Dense(16, input_shape=(4,), activation='relu'),\n",
        "      Dense(3, activation='softmax')\n",
        "  ])\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "def create_model_2():\n",
        "  model = Sequential([\n",
        "      Dense(32, input_shape=(4,), activation='relu'),\n",
        "      Dense(16, activation='relu'),\n",
        "      Dense(3, activation='softmax')\n",
        "  ])\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "#4. Train Base Models\n",
        "model1 = create_model_1()\n",
        "model2 = create_model_2()\n",
        "\n",
        "model1.fit(X_train, y_train_cat, epochs=50, verbose=0)\n",
        "model2.fit(X_train, y_train_cat, epochs=50, verbose=0)\n",
        "\n",
        "#5. Get Predictions for training data (to train meta-model)\n",
        "train_pred1 = model1.predict(X_train)\n",
        "train_pred2 = model2.predict(X_train)\n",
        "\n",
        "#Stack predictions horizontally to create meta-features\n",
        "stacked_train_features = np.hstack((train_pred1, train_pred2))\n",
        "\n",
        "#6. Train meta-model on predictions\n",
        "meta_model = LogisticRegression(max_iter=1000)\n",
        "meta_model.fit(stacked_train_features, y_train)\n",
        "\n",
        "#7. Predict on test data\n",
        "test_pred1 = model1.predict(X_test)\n",
        "test_pred2 = model2.predict(X_test)\n",
        "\n",
        "stacked_test_features = np.hstack((test_pred1, test_pred2))\n",
        "final_pred = meta_model.predict(stacked_test_features)\n",
        "\n",
        "#8. Accuracy\n",
        "print(\"Stacked Deep Learning Esemble Accuracy:\", accuracy_score(y_test, final_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02kXhZPK2p5A",
        "outputId": "661f93aa-3d23-494c-9ec2-f1acf1b6a762"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Stacked Deep Learning Esemble Accuracy: 0.9333333333333333\n"
          ]
        }
      ]
    }
  ]
}